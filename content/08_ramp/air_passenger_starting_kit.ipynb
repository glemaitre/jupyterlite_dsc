{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to RAMP platform and interaction with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAMP is a Kaggle-like platform. It is used to run data science challenge. Indeed, a challenge is organized around a specific problem for which the data and the evaluation are already defined. Participants will only have to focus on the development of the machine learning pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will present how the RAMP platform works. RAMP relies on a data science problem which is formulated in `problem.py`. It defines both data and evaluation. If you are interested, you can open this file. Otherwise, we will only used a couple of the function defined there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load the training and testing datasets available for the challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = problem.get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = problem.get_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Succently, we can check the type of features in `X` and the target that we would like to predict `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateOfDeparture</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>WeeksToDeparture</th>\n",
       "      <th>std_wtd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-06-19</td>\n",
       "      <td>ORD</td>\n",
       "      <td>DFW</td>\n",
       "      <td>12.875000</td>\n",
       "      <td>9.812647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>LAS</td>\n",
       "      <td>DEN</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>9.466734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>DEN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>10.863636</td>\n",
       "      <td>9.035883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-10-09</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ORD</td>\n",
       "      <td>11.480000</td>\n",
       "      <td>7.990202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-02-21</td>\n",
       "      <td>DEN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>9.517159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DateOfDeparture Departure Arrival  WeeksToDeparture   std_wtd\n",
       "0      2012-06-19       ORD     DFW         12.875000  9.812647\n",
       "1      2012-09-10       LAS     DEN         14.285714  9.466734\n",
       "2      2012-10-05       DEN     LAX         10.863636  9.035883\n",
       "3      2011-10-09       ATL     ORD         11.480000  7.990202\n",
       "4      2012-02-21       DEN     SFO         11.450000  9.517159"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.33129622, 10.77518151, 11.08317675, 11.16926784, 11.26936373])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target `y` corresponds to a number of passengers (modified using a `log` function). Associated with each target, we have an information in `X` related to the date (`DateOfDeparture`) and the airports of departure (`Departure`) and arrival (`Arrival`). Besides, we have the information regarding the mean (`WeeksToDeparture`) and standard deviation (`std_wtd`) of the time in weeks between the booking and the departure.\n",
    "\n",
    "So we try to answer to the following information: **With some flying information between airports, can we predict the (log) flow of passengers?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a basic scikit-learn model that could use some the data in `X` to answer this question. We will create a factory function `get_estimator()` to return the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def get_estimator():\n",
    "    cat_processor = OrdinalEncoder()\n",
    "    cat_columns = [\"Departure\", \"Arrival\"]\n",
    "\n",
    "    num_processor = \"passthrough\"\n",
    "    num_columns = [\"WeeksToDeparture\", \"std_wtd\"]\n",
    "\n",
    "    preprocessor = make_column_transformer(\n",
    "        (cat_processor, cat_columns),\n",
    "        (num_processor, num_columns),\n",
    "        remainder=\"drop\",  # drop the unused columns\n",
    "    )\n",
    "\n",
    "    return make_pipeline(preprocessor, RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, we could train and test our model using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Fold #0: 0.854\n",
      "CV Fold #1: 0.862\n",
      "CV Fold #2: 0.851\n",
      "CV Fold #3: 0.875\n",
      "CV Fold #4: 0.864\n",
      "CV Fold #5: 0.850\n",
      "CV Fold #6: 0.846\n",
      "CV Fold #7: 0.839\n",
      "RMSE = 0.855 +/- 0.011\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = get_estimator()\n",
    "cv = problem.get_cv(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(\n",
    "    model, X_train, y_train, cv=cv,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    ")\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "for cv_idx, score in enumerate(rmse_scores):\n",
    "    print(f\"CV Fold #{cv_idx}: {score:.3f}\")\n",
    "print(\n",
    "    f\"RMSE = {rmse_scores.mean():.3f} \"\n",
    "    f\"+/- {rmse_scores.std():.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAMP was developed to avoid running the last cell. Instead, the idea is to store the content of cell where `get_estimator` is defined into a file. For this challenge, the name of the file is called `estimator.py`. You can check the content of `submissions/starting_kit` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make our first kit. Alongside of the three kits, create a folder `my_first_kit` in the folder `submissions`. The command below will create a `estimator.py` file into this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting submissions/my_first_kit/estimator.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile submissions/my_first_kit/estimator.py\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def get_estimator():\n",
    "    cat_processor = OrdinalEncoder()\n",
    "    cat_columns = [\"Departure\", \"Arrival\"]\n",
    "\n",
    "    num_processor = \"passthrough\"\n",
    "    num_columns = [\"WeeksToDeparture\", \"std_wtd\"]\n",
    "\n",
    "    preprocessor = make_column_transformer(\n",
    "        (cat_processor, cat_columns),\n",
    "        (num_processor, num_columns),\n",
    "        remainder=\"drop\",  # drop the unused columns\n",
    "    )\n",
    "\n",
    "    return make_pipeline(preprocessor, RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the `estimator.py` was created, we can use the `ramp-test` command to automatically execute the evaluation on our newly created estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;178m\u001b[1mTesting Number of air passengers prediction\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading train and test files from ./data ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading cv ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mTraining submissions/my_first_kit ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 0\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   rmse      time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.323\u001b[0m  \u001b[38;5;150m1.898484\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.854\u001b[0m  \u001b[38;5;105m0.174880\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m0.886\u001b[0m  \u001b[38;5;218m0.055788\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 1\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   rmse      time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.316\u001b[0m  \u001b[38;5;150m1.230795\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.863\u001b[0m  \u001b[38;5;105m0.164316\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m0.879\u001b[0m  \u001b[38;5;218m0.054035\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 2\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   rmse      time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.321\u001b[0m  \u001b[38;5;150m1.292139\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.847\u001b[0m  \u001b[38;5;105m0.234369\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m0.875\u001b[0m  \u001b[38;5;218m0.058681\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 3\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   rmse      time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.307\u001b[0m  \u001b[38;5;150m1.593192\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.875\u001b[0m  \u001b[38;5;105m0.232582\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m0.887\u001b[0m  \u001b[38;5;218m0.073297\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 4\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   rmse      time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.317\u001b[0m  \u001b[38;5;150m1.648690\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.861\u001b[0m  \u001b[38;5;105m0.293554\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m0.901\u001b[0m  \u001b[38;5;218m0.088616\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 5\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   rmse      time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.319\u001b[0m  \u001b[38;5;150m1.798566\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.849\u001b[0m  \u001b[38;5;105m0.268945\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m0.889\u001b[0m  \u001b[38;5;218m0.085102\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 6\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   rmse      time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.313\u001b[0m  \u001b[38;5;150m2.117580\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.844\u001b[0m  \u001b[38;5;105m0.355601\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m0.882\u001b[0m  \u001b[38;5;218m0.110186\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 7\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   rmse      time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.319\u001b[0m  \u001b[38;5;150m1.936658\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.839\u001b[0m  \u001b[38;5;105m0.252511\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m0.890\u001b[0m  \u001b[38;5;218m0.093794\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mMean CV scores\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore            rmse        time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.317\u001b[0m \u001b[38;5;150m\u001b[38;5;150m±\u001b[0m\u001b[0m \u001b[38;5;150m0.0048\u001b[0m  \u001b[38;5;150m1.7\u001b[0m \u001b[38;5;150m\u001b[38;5;150m±\u001b[0m\u001b[0m \u001b[38;5;150m0.29\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m   \u001b[38;5;12m\u001b[1m0.854\u001b[0m \u001b[38;5;105m\u001b[38;5;105m±\u001b[0m\u001b[0m \u001b[38;5;105m0.011\u001b[0m  \u001b[38;5;105m0.2\u001b[0m \u001b[38;5;105m\u001b[38;5;105m±\u001b[0m\u001b[0m \u001b[38;5;105m0.06\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m0.886\u001b[0m \u001b[38;5;218m\u001b[38;5;218m±\u001b[0m\u001b[0m \u001b[38;5;218m0.0073\u001b[0m  \u001b[38;5;218m0.1\u001b[0m \u001b[38;5;218m\u001b[38;5;218m±\u001b[0m\u001b[0m \u001b[38;5;218m0.02\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mBagged scores\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   rmse\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.820\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m0.849\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!ramp-test --submission my_first_kit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command is the exact replica of what would happen on our server when you will submit your file `estimator.py` on https://ramp.studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now make a demo on submitting this kit on the RAMP platform."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
